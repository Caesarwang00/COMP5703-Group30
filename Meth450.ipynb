{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bfd1c2",
   "metadata": {},
   "source": [
    "# Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d58e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Package Versions ===\n",
      "Python: 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]\n",
      "NumPy: 1.23.3\n",
      "Pandas: 2.0.3\n",
      "Scikit-learn: 1.3.0\n",
      "XGBoost: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "# 打印代码所用关键包的版本信息\n",
    "print(\"\\n=== Package Versions ===\")\n",
    "print(f\"Python: {os.sys.version}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\") \n",
    "print(f\"XGBoost: {xgboost.__version__}\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f612c",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd47af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "开始 GBM 亚型识别（DNA甲基化450 + XGBoost）\n",
      "============================================================\n",
      "[INFO] 匹配成功样本数: 85\n",
      "[INFO] 类别分布: {'Mesenchymal': 26, 'Classical': 26, 'Proneural': 22, 'Neural': 11}\n",
      "[INFO] 编码后类别: {'Classical': 0, 'Mesenchymal': 1, 'Neural': 2, 'Proneural': 3}\n",
      "[INFO] 特征数（缺失率≤50%）: 396058\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "=== 最优参数 ===\n",
      "{'kbest__k': 50, 'xgb__colsample_bytree': 0.8, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100, 'xgb__subsample': 1.0}\n",
      "CV f1_macro: 0.5564\n",
      "\n",
      "=== 测试集指标 ===\n",
      "test_accuracy: 0.5769\n",
      "test_precision_macro: 0.5519\n",
      "test_recall_macro: 0.5387\n",
      "test_f1_macro: 0.5235\n",
      "test_precision_weighted: 0.6093\n",
      "test_recall_weighted: 0.5769\n",
      "test_f1_weighted: 0.5674\n",
      "\n",
      "=== 测试集分类报告 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Classical       0.64      0.88      0.74         8\n",
      " Mesenchymal       0.75      0.38      0.50         8\n",
      "      Neural       0.25      0.33      0.29         3\n",
      "   Proneural       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.58        26\n",
      "   macro avg       0.55      0.54      0.52        26\n",
      "weighted avg       0.61      0.58      0.57        26\n",
      "\n",
      "\n",
      "[完成]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost\n",
    "from typing import Tuple, Dict, List\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class GBMSubtypeClassifier:\n",
    "    \"\"\"\n",
    "    改用XGBoost进行GBM亚型分类：\n",
    "      - 读取临床与甲基化数据\n",
    "      - 解析短条形码并匹配原发瘤有亚型标签的样本\n",
    "      - 预处理（缺失率过滤 + 均值填充 + 标准化 + ANOVA特征选择）\n",
    "      - XGBoost + 分层CV的网格搜索\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir: str):\n",
    "        self.base_dir = base_dir\n",
    "        self.files = {\n",
    "            \"meth450\": os.path.join(base_dir, \"HumanMethylation450\"),\n",
    "            \"clinical\": os.path.join(base_dir, \"TCGA.GBM.sampleMap_GBM_clinicalMatrix\"),\n",
    "        }\n",
    "        # 短条形码：例如 TCGA-06-1234-01（最后两位是样本类型，01=Primary Tumor）\n",
    "        self.short_re = re.compile(r'^(TCGA-[A-Za-z0-9]{2}-[A-Za-z0-9]{4}-(\\d{2}))')\n",
    "        self.pipeline = None\n",
    "        self.label_encoder = None\n",
    "\n",
    "    # ---------- 基础工具 ----------\n",
    "    def _to_sample_short(self, s: str) -> str:\n",
    "        if not isinstance(s, str):\n",
    "            return None\n",
    "        m = self.short_re.match(s.strip())\n",
    "        return m.group(1) if m else None\n",
    "\n",
    "    def _is_primary_by_short(self, short_id: str) -> bool:\n",
    "        if not isinstance(short_id, str):\n",
    "            return False\n",
    "        m = self.short_re.match(short_id)\n",
    "        if not m:\n",
    "            return False\n",
    "        return m.group(2) == \"01\"  # 01=Primary Tumor\n",
    "\n",
    "    def _read_tsv(self, path: str, nrows=None) -> pd.DataFrame:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"文件不存在: {path}\")\n",
    "        return pd.read_csv(path, sep=\"\\t\", low_memory=False, nrows=nrows)\n",
    "\n",
    "    # ---------- 数据读取与匹配 ----------\n",
    "    def _load_clinical(self) -> pd.DataFrame:\n",
    "        clin = self._read_tsv(self.files[\"clinical\"])\n",
    "\n",
    "        # 样本ID列\n",
    "        sid_col = None\n",
    "        for col in [\"sampleID\", \"bcr_sample_barcode\"]:\n",
    "            if col in clin.columns:\n",
    "                sid_col = col\n",
    "                break\n",
    "        if sid_col is None:\n",
    "            raise ValueError(\"临床数据中未找到样本ID列（sampleID / bcr_sample_barcode）\")\n",
    "\n",
    "        # 亚型列\n",
    "        subtype_col = None\n",
    "        for col in [\"GeneExp_Subtype\", \"Subtype_mRNA\", \"Subtype\", \"GeneExp_Subtype \"]:\n",
    "            if col in clin.columns:\n",
    "                subtype_col = col\n",
    "                break\n",
    "        if subtype_col is None:\n",
    "            raise ValueError(\"临床数据中未找到亚型列（GeneExp_Subtype / Subtype_mRNA 等）\")\n",
    "\n",
    "        # 洁净化：短条形码 + 是否原发\n",
    "        clin[\"short_id\"]   = clin[sid_col].astype(str).apply(self._to_sample_short)\n",
    "        clin[\"is_primary\"] = clin[\"short_id\"].apply(self._is_primary_by_short)\n",
    "\n",
    "        # 规范化亚型标签：去两端空格、首字母大写\n",
    "        def _norm_subtype(x):\n",
    "            if pd.isna(x):\n",
    "                return x\n",
    "            s = str(x).strip()\n",
    "            return s[:1].upper() + s[1:].lower() if s else s\n",
    "\n",
    "        clin[\"subtype\"] = clin[subtype_col].apply(_norm_subtype)\n",
    "\n",
    "        # 保留：原发 + 有短ID + 有亚型\n",
    "        valid = clin[(clin[\"is_primary\"]) & (clin[\"short_id\"].notna()) & (clin[\"subtype\"].notna())]\n",
    "        return valid[[\"short_id\", \"subtype\"]].drop_duplicates()\n",
    "\n",
    "    def _load_methylation(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        返回形状为 (样本, 特征) 的数值矩阵：\n",
    "          - 自动猜测矩阵朝向：若列名不是TCGA，则看第一列是否是TCGA样本并转置\n",
    "          - 只保留列名/行值里带TCGA的样本\n",
    "        \"\"\"\n",
    "        df = self._read_tsv(self.files[\"meth450\"])\n",
    "\n",
    "        # 若首列为注释列（如 probe/gene），设为索引\n",
    "        first_col_lower = str(df.columns[0]).strip().lower()\n",
    "        if first_col_lower in {\n",
    "            \"gene\", \"genes\", \"hugo\", \"symbol\", \"gene symbol\",\n",
    "            \"id\", \"probe\", \"probes\", \"composite element ref\", \"sample\"\n",
    "        }:\n",
    "            df = df.set_index(df.columns[0])\n",
    "\n",
    "        # 判断样本是在列还是在行\n",
    "        def _cols_have_tcga(_df):\n",
    "            return any(str(c).startswith(\"TCGA-\") for c in _df.columns)\n",
    "\n",
    "        if not _cols_have_tcga(df):\n",
    "            # 如果第一列/索引是样本ID\n",
    "            first_col = df.columns[0]\n",
    "            if df[first_col].astype(str).str.startswith(\"TCGA-\").any():\n",
    "                df = df.set_index(first_col).transpose()\n",
    "\n",
    "        # 只保留TCGA列\n",
    "        tcga_cols = [c for c in df.columns if str(c).startswith(\"TCGA-\")]\n",
    "        if len(tcga_cols) == 0:\n",
    "            # 尝试从索引转列（极端情况）\n",
    "            if any(str(i).startswith(\"TCGA-\") for i in df.index):\n",
    "                df = df.transpose()\n",
    "                tcga_cols = [c for c in df.columns if str(c).startswith(\"TCGA-\")]\n",
    "        if len(tcga_cols) == 0:\n",
    "            raise ValueError(\"甲基化数据中未发现TCGA样本列/行\")\n",
    "\n",
    "        df = df[tcga_cols]\n",
    "        # 转为数值\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "        # 置换：需要 (样本, 特征)\n",
    "        X = df.transpose().copy()\n",
    "        X.index.name = \"sample_barcode\"\n",
    "        return X\n",
    "\n",
    "    def _match_on_short_id(self, X_meth: pd.DataFrame, clin: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        将甲基化样本条形码映射为短条形码，与临床表的 short_id 匹配。\n",
    "        返回 X(样本x特征) 与 y(样本标签Series，index与X一致)。\n",
    "        \"\"\"\n",
    "        # 从条形码映射到短ID\n",
    "        short_ids = X_meth.index.to_series().astype(str).apply(self._to_sample_short)\n",
    "        keep_mask = short_ids.notna()\n",
    "        X_meth = X_meth.loc[keep_mask].copy()\n",
    "        short_ids = short_ids.loc[keep_mask]\n",
    "\n",
    "        # 有些短ID可能重复（同一短ID对应多个测序批次），这里保留首次出现\n",
    "        # 也可以选择分组取均值：X_meth.groupby(short_ids).mean()\n",
    "        # 为避免特征数巨大导致 groupby 内存压力，这里采用\"首个样本\"策略：\n",
    "        dedup_index = ~short_ids.duplicated()\n",
    "        X_meth = X_meth.loc[dedup_index]\n",
    "        short_ids = short_ids.loc[dedup_index]\n",
    "\n",
    "        # 与临床匹配\n",
    "        short_to_subtype = dict(zip(clin[\"short_id\"], clin[\"subtype\"]))\n",
    "        y = short_ids.map(short_to_subtype)\n",
    "\n",
    "        match_mask = y.notna()\n",
    "        X_matched = X_meth.loc[match_mask].copy()\n",
    "        y_matched = y.loc[match_mask].copy()\n",
    "\n",
    "        # 统一索引为短ID（更直观）\n",
    "        X_matched.index = y_matched.values  # 先临时放 subtype\n",
    "        X_matched.insert(0, \"short_id\", short_ids.loc[match_mask].values)\n",
    "        # 把短ID设成索引，再把 y 的索引对齐\n",
    "        X_matched = X_matched.set_index(\"short_id\")\n",
    "        y_matched.index = X_matched.index\n",
    "\n",
    "        # 恢复 X 的真实行索引为短ID（而不是subtype）\n",
    "        # 需要把第一步替换的index还原：\n",
    "        # 此时 X_matched 的第一列是特征，index 是 short_id，行内没有样本条形码，不影响后续\n",
    "        return X_matched, y_matched\n",
    "\n",
    "    # ---------- 数据准备 ----------\n",
    "    def prepare_data(self, min_samples_per_class: int = 10, max_missing_ratio: float = 0.5) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        clin = self._load_clinical()\n",
    "        X_meth = self._load_methylation()\n",
    "\n",
    "        # 匹配\n",
    "        X, y = self._match_on_short_id(X_meth, clin)\n",
    "\n",
    "        # 过滤类别：至少 min_samples_per_class\n",
    "        vc = y.value_counts()\n",
    "        valid_classes = vc[vc >= min_samples_per_class].index.tolist()\n",
    "        keep = y.isin(valid_classes)\n",
    "        X, y = X.loc[keep], y.loc[keep]\n",
    "\n",
    "        # 缺失率过滤（按列=特征）\n",
    "        miss_ratio = X.isna().mean(axis=0)\n",
    "        X = X.loc[:, miss_ratio <= max_missing_ratio]\n",
    "\n",
    "        # 均值填充\n",
    "        X = X.fillna(X.mean())\n",
    "\n",
    "        # 标签编码（XGBoost需要数值标签）\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        y_encoded = pd.Series(self.label_encoder.fit_transform(y), index=y.index)\n",
    "\n",
    "        # 重置索引（模型不要依赖 short_id）\n",
    "        X = X.reset_index(drop=True)\n",
    "        y_encoded = y_encoded.reset_index(drop=True)\n",
    "\n",
    "        # 基本信息\n",
    "        print(f\"[INFO] 匹配成功样本数: {len(y_encoded)}\")\n",
    "        print(f\"[INFO] 类别分布: {pd.Series(y).value_counts().to_dict()}\")\n",
    "        print(f\"[INFO] 编码后类别: {dict(zip(self.label_encoder.classes_, range(len(self.label_encoder.classes_))))}\")\n",
    "        print(f\"[INFO] 特征数（缺失率≤{int(max_missing_ratio*100)}%）: {X.shape[1]}\")\n",
    "        return X, y_encoded\n",
    "\n",
    "    # ---------- 训练与评估 ----------\n",
    "    def train_and_eval(self, X: pd.DataFrame, y: pd.Series, test_size: float = 0.3, random_state: int = 42) -> Dict:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "\n",
    "        # 根据样本规模动态设置 k（不超过特征数/训练样本数的一半）\n",
    "        k_max = min(500, X_train.shape[1], max(50, X_train.shape[0] // 2))\n",
    "        k_grid = sorted(set([\n",
    "            min(50, X_train.shape[1]),\n",
    "            min(100, X_train.shape[1]),\n",
    "            min(200, X_train.shape[1], k_max)\n",
    "        ]))\n",
    "\n",
    "        # 计算类别权重\n",
    "        from sklearn.utils.class_weight import compute_class_weight\n",
    "        classes = np.unique(y_train)\n",
    "        class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "        sample_weights = np.array([class_weights[i] for i in y_train])\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "            (\"kbest\", SelectKBest(score_func=f_classif, k=k_grid[-1] if k_grid else 50)),\n",
    "            (\"xgb\", XGBClassifier(\n",
    "                objective='multi:softprob',  # 多分类\n",
    "                eval_metric='mlogloss',      # 多分类对数损失\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0  # 减少输出\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        # CV 折数 = min(5, 最小类样本数)\n",
    "        min_per_class = int(pd.Series(y_train).value_counts().min())\n",
    "        cv_folds = max(2, min(5, min_per_class))\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "        param_grid = {\n",
    "            \"kbest__k\": k_grid,\n",
    "            \"xgb__n_estimators\": [100, 200],\n",
    "            \"xgb__max_depth\": [3, 6, 9],\n",
    "            \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"xgb__subsample\": [0.8, 1.0],\n",
    "            \"xgb__colsample_bytree\": [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        gs = GridSearchCV(\n",
    "            pipe, param_grid=param_grid, cv=cv, n_jobs=-1,\n",
    "            scoring=\"f1_macro\", verbose=1\n",
    "        )\n",
    "        gs.fit(X_train, y_train)\n",
    "        self.pipeline = gs.best_estimator_\n",
    "\n",
    "        y_pred_train = self.pipeline.predict(X_train)\n",
    "        y_pred_test  = self.pipeline.predict(X_test)\n",
    "\n",
    "        # 将数值标签转换回原始标签进行报告\n",
    "        y_train_orig = self.label_encoder.inverse_transform(y_train)\n",
    "        y_test_orig = self.label_encoder.inverse_transform(y_test)\n",
    "        y_pred_train_orig = self.label_encoder.inverse_transform(y_pred_train)\n",
    "        y_pred_test_orig = self.label_encoder.inverse_transform(y_pred_test)\n",
    "\n",
    "        metrics = {\n",
    "            \"best_params\": gs.best_params_,\n",
    "            \"cv_f1_macro\": float(gs.best_score_),\n",
    "            \"train_accuracy\": float(accuracy_score(y_train, y_pred_train)),\n",
    "            \"test_accuracy\":  float(accuracy_score(y_test,  y_pred_test)),\n",
    "            \"test_precision_macro\": float(precision_score(y_test, y_pred_test, average=\"macro\")),\n",
    "            \"test_recall_macro\":    float(recall_score(y_test, y_pred_test, average=\"macro\")),\n",
    "            \"test_f1_macro\":        float(f1_score(y_test, y_pred_test, average=\"macro\")),\n",
    "            \"test_precision_weighted\": float(precision_score(y_test, y_pred_test, average=\"weighted\")),\n",
    "            \"test_recall_weighted\":    float(recall_score(y_test, y_pred_test, average=\"weighted\")),\n",
    "            \"test_f1_weighted\":        float(f1_score(y_test, y_pred_test, average=\"weighted\")),\n",
    "        }\n",
    "\n",
    "        print(\"\\n=== 最优参数 ===\")\n",
    "        print(metrics[\"best_params\"])\n",
    "        print(f\"CV f1_macro: {metrics['cv_f1_macro']:.4f}\")\n",
    "\n",
    "        print(\"\\n=== 测试集指标 ===\")\n",
    "        for k in [\"test_accuracy\",\"test_precision_macro\",\"test_recall_macro\",\"test_f1_macro\",\n",
    "                  \"test_precision_weighted\",\"test_recall_weighted\",\"test_f1_weighted\"]:\n",
    "            print(f\"{k}: {metrics[k]:.4f}\")\n",
    "\n",
    "        print(\"\\n=== 测试集分类报告 ===\")\n",
    "        print(classification_report(y_test_orig, y_pred_test_orig))\n",
    "\n",
    "    # ---------- 一键运行 ----------\n",
    "    def run(self, min_samples_per_class: int = 10) -> Dict:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"开始 GBM 亚型识别（DNA甲基化450 + XGBoost）\")\n",
    "        print(\"=\" * 60)\n",
    "        X, y = self.prepare_data(min_samples_per_class=min_samples_per_class)\n",
    "        results = self.train_and_eval(X, y)\n",
    "        print(\"\\n[完成]\")\n",
    "        return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    BASE_DIR = \"/Volumes/LaCie/data\" \n",
    "    clf = GBMSubtypeClassifier(BASE_DIR)\n",
    "    results = clf.run(min_samples_per_class=10)\n",
    "    return clf, results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clf, results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
